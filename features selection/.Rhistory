example$cyl <- as.factor(example$cyl)
example$vs <- as.factor(example$vs)
example$am <- as.factor(example$am)
example$gear <- as.factor(example$gear)
str(example)
str(example)
sparse_matrix <- Matrix::sparse.model.matrix(mpg ~ .-1,data = example)
sparse_matrix
output_vector <- example[,"am"]==1
output_vector
library(readr)
library(stringr)
library(caret)
library(car
)
dummyVars(~ )
str(example)
dummyVars(~ cyl + vs + am + gear, data=example)
vars <- dummyVars(~ cyl + vs + am + gear, data=example)
vars
predict(vars,example[,-1])
ohe_feats <- c("cyl","vs","am","gear")
vars <- dummyVars(~ cyl + vs + am + gear, data=example)
example_vars <- as.data.frame(predict(vars,example[,-1]))
example_combined <- cbind(example[,-c(colnames(example) %in% ohe_feats)],example_vars)
example_combined
example_combined <- cbind(example[,-c(which(colnames(example) %in% ohe_feats))],example_vars)
example_combined
example_combined <- cbind(example[,1],example_vars)
example_combined
str(example_combined)
names(example_combined$`example[, 1]`) <- "labels"
example_combined
names(example_combined$`example[, 1]`)
names(example_combined$`example[, 1]`) = c("labels")
names(example_combined)
names(example_combined)[1]
names(example_combined)[1]="labels"
example_combined
```{r}
data(agaricus.train, package='xgboost')
data(agaricus.test, package='xgboost')
train <- agaricus.train
test <- agaricus.test
class(train$data)
#model simulation
bst <- xgboost(data = train$data, label = train$label, max.depth = 2, eta = 1, nround = 2, objective = "binary:logistic")
#predict
pred <- predict(bst, test$data)
#cross-vilidation
cv.res <- xgb.cv(data = train$data,label = train$label,
max.depth =2, eta = 1, nround = 2,
objective = "binary:logistic",nfold = 5)
model <- xgb.dump(bst,with.stats = TRUE)
model[1:10]
names <- dimnames(data.matrix(example_combined[,-1]))
names
names <- dimnames(data.matrix(example_combined[,-1]))[[2]]
names
names <- dimnames(data.matrix(train[,-1]))[[2]]
example <- mtcars[,c(1,2,8,9,10)]
example$cyl <- as.factor(example$cyl)
example$vs <- as.factor(example$vs)
example$am <- as.factor(example$am)
example$gear <- as.factor(example$gear)
str(example)
#转换分类变量为“独热向量”
sparse_matrix <- Matrix::sparse.model.matrix(mpg ~ .-1,data = example)
#转换目标变量
sparse_matrix
head(sparse_matrix)
library(caret)
#独热编码分类特征
ohe_feats <- c("cyl","vs","am","gear")
vars <- dummyVars(~ cyl + vs + am + gear, data=example)
example_vars <- as.data.frame(predict(vars,example[,-1]))
example_combined <- cbind(example[,1],example_vars)
names(example_combined)[1]="labels"
head(example_combined)
library(readxl)
library(dplyr)
example <- read_excel("C:\\Users\\HP\\Desktop\\example\\列表--2016-09-28.xls",col_names = TRUE)
View(example)
colnames(example)
example[1,]
DT::datatable(example)
head(example)
example <- example[,c("领域","地区","竞争力","爆发力")]
DT::datatable(example)
example <- example[,c("竞争力","爆发力")]
DT::datatable(example)
example <- example[,c("爆发力")]
DT::datatable(example)
library(ggplot2)
example <- read_excel("C:\\Users\\HP\\Desktop\\example\\列表--2016-09-28.xls",col_names = TRUE)
head(example)
p <- ggplot(data=example, aes(x=地区,fill=as.factor(领域))) +
geom_bar(stat = "bin",alpha = 0.8) +
labs(x = '地区', y = '频数') +
ggtitle("地域分布") +
coord_flip() +
theme(text = element_text(family = 'SimSun'))
p
p <- ggplot(data=example, aes(x=地区,fill=as.factor(领域))) +
geom_bar(stat = "count",alpha = 0.8) +
labs(x = '地区', y = '频数') +
ggtitle("地域分布") +
coord_flip() +
theme(text = element_text(family = 'SimSun'))
p
library(plotly)
p
library(plotly)
plotly::ggplotly(p)
data("cars")
cars
p <- ggplot(data=cars, aes(x=speed,y = dist)) +
geom_bar(stat = "identity",alpha = 0.8) +
labs(x = '地区', y = '频数') +
ggtitle("地域分布") +
coord_flip() +
theme(text = element_text(family = 'SimSun'))
p
plotly::ggplotly(p)
str(example)
library(readxl)
library(dplyr)
example <- read_excel("C:\\Users\\HP\\Desktop\\example\\列表--2016-09-28.xls",col_names = TRUE)
DT::datatable(example)
library(flexdashboard)
library(xlsx)
library(ggplot2)
#Read US GDP Data Set from FED Excel File
dtGDP <- read.xlsx('fredgraph.xls',sheetName = 'GDP')
#Read US Unemployment Rate and ISM PCI Index Data Set from FED Excel File
dtOtherIndicators <- read.xlsx('fredgraph.xls',sheetName = 'Sheet2')
library(xlsx)
library(readxl)
dtGDP <- read.xlsx('fredgraph.xls',sheetName = 'GDP')
#Read US Unemployment Rate and ISM PCI Index Data Set from FED Excel File
dtOtherIndicators <- read.xlsx('fredgraph.xls',sheetName = 'Sheet2')
dtGDP <- read_excel('fredgraph.xls',sheetName = 'GDP')
cars
library(mlr)
install.packages("mlr")
library(mlr)
library(mlr)
listLearners()
listLearners("classif","twoclass")
listLearners("classif","twoclass")[c("class","package")]
sessionInfo()
sessionInfo("data.table")
library(data.table)
library(mlr)
library(mlr)
listFilterMethods()
listMeasures()
getLearnerProperties()
getLearnerProperties(learner )
getLearnerProperties(learner)
getLearnerProperties(learner)
getLearnerProperties(learner)
getLearnerProperties(SVM)
getLearnerProperties(svm)
listLearners()
getLearnerProperties(classif.avNNet)
library(rJava)
library(rJava)
s <- .jnew("java","Hello world")
.jinit()
s <- .jnew("java","Hello world")
s <- .jnew("java/lang","Hello world")
s <- .jnew("java/lang/string","Hello world")
s <- .jnew("java/lang/String","Hello world")
s
s <- .jnew("java/lang/Number","999")
s <- .jnew("java/lang/Numbers","999")
s
f <- .jnew("java/awt/Frame","Hello")
f
.jcall(f,,"setVisible",TRUE)
sapply(c("dplyr","rvest","ggmap","leaflet","RColorBrewer"), library)
sapply(c("dplyr","rvest","ggmap","leaflet","RColorBrewer"), library)
apply(c("dplyr","rvest","ggmap","leaflet","RColorBrewer"), library)
apply(c("dplyr","rvest","ggmap","leaflet","RColorBrewer"), FUN = library)
lapply(c("dplyr","rvest","ggmap","leaflet","RColorBrewer"), library)
lapply(c("dplyr","rvest","ggmap","leaflet","RColorBrewer"), library)
lapply(c("dplyr","rvest","ggmap","leaflet","RColorBrewer"), library,character.only = TRUE)
url <- html("http://www.tjhi.com.cn/html/index.html")
url <- html("http://www.tjhi.com.cn/html/index.html")
url <- read_html("http://www.tjhi.com.cn/html/index.html")
url
selector_name <- "MsgIndexNewTopName"
fnames <- html_nodes(x = url,css = selector_name) %>%
html_text()
selector_name <- "MsgIndexNewList"
fnames <- html_nodes(x = url,css = selector_name) %>%
html_text()
head(fnames)
selector_name <- "MsgIndexLeft"
fnames <- html_nodes(x = url,css = selector_name) %>%
html_text()
head(fnames)
url <- read_html("http://www.visitithaca.com/attractions/wineries.html")
url <- read_html("http://www.tjhi.com.cn/ShowInfoPage/18610099-e03d-4f96-945b-0175e9214769.html")
selector_name <- "mbctra_resourceView"
fnames <- html_nodes(x = url,css = selector_name) %>%
html_text()
head(fnames)
library(mlr)
data("iris")
iris
length(iris)
iris.data <- iris[,-length(iris)]
View(iris.data)
iris.targer <- iris[,length(iris)]
class(iris.targer)
scale(iris.data,center = TRUE,scale = TRUE)
seq(length(iris.data))
max(iris)
max(iris.data)
max.col(iris.data)
iris.data
maxmin <- function(col){
maxmin <- (col-min(col)/(max(col)-min(col)))
return(maxmin)
}
maxmin(iris.data[,1])
min(iris.data[,1])
max(iris.data[,1])
(max(iris.data[,1])-min(iris.data[,1]))
maxmin <- function(col){
maxmin <- (col-min(col))/(max(col)-min(col))
return(maxmin)
}
maxmin(iris.data[,1])
maxmin(iris.data)
normalize(iris.data)
iris.data <- iris[,-length(iris)]
maxmin(iris.data)
normalize(iris.data)
scale(iris.data,center = TRUE,scale = TRUE)
norm <- function(col){
norm = col/(sqrt(sum(col*col)))
return(norm)
}
norm(iris.data[,1])
sum(norm(iris.data[,1]))
norm(iris.data)
norm <- function(col){
norm = col/(sqrt((col*col)))
return(norm)
}
norm(iris.data)
norm <- function(data,col){
norm = apply(data,2,function(x){x/sqrt(sum(x*x))})
return(norm)
}
norm <- function(data){
norm = apply(data,2,function(x){x/sqrt(sum(x*x))})
return(norm)
}
norm(iris.data)
sum(iris.data[,1]^2)
sqrt(sum(iris.data[,1]^2))
iris.data[1,1]/sqrt(sum(iris.data[,1]^2))
norm <- function(data){
norm = apply(data,1,function(x){x/sqrt(sum(x^2))})
return(norm)
}
norm(iris.data)
norm <- function(data){
norm = apply(data,1,function(x){x/sqrt(sum(x^2))})
T(norm)
return(norm)
}
norm(iris.data)
norm <- function(data){
norm = apply(data,1,function(x){x/sqrt(sum(x^2))})
norm = t(norm)
return(norm)
}
norm(iris.data)
norm(iris.data)[1]
norm(iris.data)[1,1]
norm(iris.data)[1:4]
norm(iris.data)[1:4,]
norm(iris.data)[1,]
bina <- function(data,threshold){
ifelse(data >= threshold,1,0)
}
bina(iris.data)
bina(iris.data,3)
iris.data[150,]
bina <- function(data,threshold){
ifelse(data > threshold,1,0)
}
bina(iris.data,3)
bina(iris.data,threshold = 3)
dummyVars(iris.targer)
library(caret)
dummyVars(iris.targer)
names(iris)
dummyVars(~Species,data = iris)
predict(var,iris.targer)
var
var <- dummyVars(~ Species,data = iris)
var
predict(var,iris.targer)
predict(var,iris["Species"])
rep(4)
rep(1,4)
new = rep("NA",4)
new = rep(NA,4)
rbind(new,iris.data)
library(Hmisc)
impute(iris.data,mean)
knitr::opts_chunk$set(echo = TRUE,highlight = TRUE,tidy= TRUE)
namedList(iris.data)
namedList(iris.data,1:4)
names(iris.data)
namedList(iris.data)
names(iris.data)
iris.data <- iris.data %>%
mutate(x3 = Sepal.Length*Sepal.Width)
library(caret)
iris.data <- iris.data %>%
mutate(x3 = Sepal.Length*Sepal.Width)
library(dplyr)
iris.data <- iris.data %>%
mutate(x3 = Sepal.Length*Sepal.Width)
iris.data
iris.data <- iris.data %>%
mutate_each(log())
iris.data <- iris.data %>%
mutate_each(in())
iris.data <- iris.data %>%
mutate_each(log1p())
iris.data <- iris.data %>%
mutate_each(log1p(x))
iris.data <- iris.data %>%
mutate_each(funs(log1p))
iris.data
library(mlr)
listFilterMethods()
train.task <- makeClassifTask(data = iris,target = "Species")
var_imp <- generateFilterValuesData(train.task,method = "variance")
plotFilterValues(var_imp,feat.type.cols = TRUE)
plotFilterValues(var_imp,feat.type.cols = TRUE,fvalues = TRUE)
plotFilterValues(var_imp,feat.type.cols = TRUE,fvalues = 3)
generateFilterValuesData(train.task, method = "variance",
nselect = 3)
fvalue <- generateFilterValuesData(train.task, method = "variance",
nselect = 3)
plotFilterValues(var_imp,feat.type.cols = TRUE,fvalues = fvalue )
var_imp
plotFilterValues(var_imp,feat.type.cols = TRUE )
plotFilterValues(var_imp,feat.type.cols = TRUE,n.show = 3 )
var_imp <- generateFilterValuesData(train.task,method = "variance",nselect = 3)
var_imp
plotFilterValues(var_imp,feat.type.cols = TRUE,n.show = 3)
listFilterMethods()
var_imp <- generateFilterValuesData(train.task,method = "linear.correlation",nselect = 3)
train.task <- makeClassifTask(data = iris,target = "Species")
generateFilterValuesData(train.task,method = "linear.correlation")
train.task <- makeRegrTask(data = iris.data,target = "Sepal.Width")
generateFilterValuesData(train.task,method = "linear.correlation")
var_imp <- generateFilterValuesData(train.task,method = "linear.correlation")
var_imp
plotFilterValues(var_imp,feat.type.cols = TRUE,n.show = 3)
listFilterMethods()
train.task <- makeClassifTask(data = iris,target = "Species")
#查看变量选择可选方法
var_imp <- generateFilterValuesData(train.task,method = " chi.squared")
var_imp
var_imp <- generateFilterValuesData(train.task,method = "chi.squared")
var_imp
plotFilterValues(var_imp,feat.type.cols = TRUE)
corrplot(cor(iris.data))
library(corrplot)
corrplot(cor(iris.data))
corrplot(cor(iris.data),order="hclust")
var_imp <- generateFilterValuesData(train.task,method = "information.gain")
var_imp
plotFilterValues(var_imp,feat.type.cols = TRUE)
listLearners("classif","twoclass")[c("class","package")]
listLearners("classif","twoclass")[c("class","package")]
listLearners()
listLearners("classif")
listLearners("classif")[multiclass]
listLearners("classif")["multiclass"]
listLearners("classif")[c("classif","multiclass")]
listLearners("classif","multiclass")[c("class","package")]
gbm_learner <- makeLearner("classif.gbm",predict.type = "response")
gbm_learner$par.vals <- list(laplace = 1)
nB_models <- mlr::train(gbm_learner,train.task)
nB_models
trainLearner(gbm_learner,train.task)
predict(nB_models,train.task)
predict(nB_model,train.task)
nB_model <- trainLearner(gbm_learner,train.task)
predict(nB_model,train.task)
nB_models <- mlr::train(gbm_learner,train.task)
nB_models
nB_predict <- predict(nB_models,train.task)
nB_predict
nB_prediction <- nB_predict$data$response
confusionMatrix(iris$Species,nB_prediction)
iris.pc<-select(iris,Easy_Reservation:Recommend)%>%
prcomp()
iris.pc<-prcomp(iris)
iris.pc<-prcomp(iris.data)
summary(iris.pc)
plot(iris.pc,type="l",family ="Songti SC",main="PCA陡坡图")
biplot(iris.pc,family ="Songti SC",main="PCA双标图",cex=c(0.5,1),xlim=c(-0.06,0.04))
iris.pc
iris.pc$sdev
iris.pc$x
iris.pc$rotation
library(MASS)
fit_lda = lda(Species~., data = iris)
fit_lda
names(fit_lda1)
names(fit_lda)
fit_lda$xlevels
fit_lda$lev
fit_lda$svd
fit_lda$means
listLearners("classif","multiclass")[c("class","package")]
setwd("C:/Users/HP/Desktop/imbalance data/features selection")
data("iris")
#特征矩阵
iris.data <- iris[,-length(iris)]
#目标向量
iris.targer <- iris[,length(iris)]
names(iris)
m <- glm(Species ~ ., data = iris, family = "binomial")
m
library(MASS)
m <- glm(Species ~ ., data = iris, family = "binomial")
selecting <- step(m,direction = "backward")
selecting$anova
var <- dummyVars(~ Species,data = iris)
library(caret)
var <- dummyVars(~ Species,data = iris)
predict(var,iris["Species"])
target <- as.data.frame(predict(var,iris["Species"]))
library(glmnet)
library(glmnet)
require(mlbench)
require(mlbench)
data(Sonar)
str(Sonar)
library(glmnet)
glmnet(iris.data,iris.targer,family = "binomial",alpha = 1)
glmnet(iris.data,iris.targer,family = "multinomial",alpha = 1)
glmnet(iris.data,iris.targer,family = "multinomial",alpha = 1)
iris.cbind <- cbind(iris.data,target)
View(iris.cbind)
str(iris.cbind)
glmnet(iris.data,iris.cbind,family = "multinomial",alpha = 1)
x=matrix(rnorm(100*20),100,20)
x
g4=sample(1:4,100,replace=TRUE)
g4
class(g4)
class(iris)
str(iris)
target
iris.targer
as.numeric(iris.targer)
targ <- as.numeric(iris.targer)
glmnet(iris.data,targ,family = "multinomial",alpha = 1)
class(x)
iri <- as.matrix(iris.data)
iri
glmnet(iri,targ,family = "multinomial",alpha = 1)
iris.matrix <- as.matrix(iris.data)
target <- as.numeric(iris.targer)
#Lasso回归
library(glmnet)
#alpha = 1为Lasso回归，alpha=0为岭回归
r2 <- glmnet(iris.matrix,target,family = "multinomial",alpha = 1)
r2.cv <- cv.glmnet(iris.matrix,target,family = "multinomial",alpha = 1,nfolds = 10)
plot(r2.cv)
r2.cv
r2.cv$lambda.min
r2.min <- glmnet(train.x,train.y, family = "binomial", alpha = 1, lambda = r2.cv$lambda.min)
r2.min <- glmnet(iris.matrix,target,family = "multinomial", alpha = 1, lambda = r2.cv$lambda.min)
r2.min_coef <- coef(r2.min)
r2.min_coef
r2.min_coef[which(r2.min_coef != 0)]
rownames(r2.min_coef)[which(r2.min_coef != 0)]
SuperLearner::screen.glmnet
library(SuperLearner)
SuperLearner::screen.glmnet(target,iris.matrix,family = "multinominal",alpha = 1,minscreen = 2)
SuperLearner::screen.glmnet(iris.matrix,target,family = "multinomial",alpha = 1,minscreen = 2)
r2.min
coef(r2.min)
r2.min_coef <- coef(r2.min)
str(r2.min_coef)
r2.min_coef$`1`
str(r2.min)
r2.min_coef <- coef(r2.min)
which(r2.min_coef != 0)
rownames(r2.min_coef)
r2.min
r2.min$a0
r2.min$beta
str(r2.min)
r2.min$dfmat
coef(r2.min)

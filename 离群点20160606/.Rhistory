head(cars)
eval(cars)
substitute(cars$speed)
substitute(cars$dist)
outlierKD <- function(dt, var) {
var_name <- eval(substitute(var),eval(dt))
tot <- sum(!is.na(var_name))
na1 <- sum(is.na(var_name))
m1 <- mean(var_name, na.rm = T)
par(mfrow=c(2, 2), oma=c(0,0,3,0))
boxplot(var_name, main="With outliers")
hist(var_name, main="With outliers", xlab=NA, ylab=NA)
outlier <- boxplot.stats(var_name)$out
mo <- mean(outlier)
var_name <- ifelse(var_name %in% outlier, NA, var_name)
boxplot(var_name, main="Without outliers")
hist(var_name, main="Without outliers", xlab=NA, ylab=NA)
title("Outlier Check", outer=TRUE)
na2 <- sum(is.na(var_name))
cat("Outliers identified:", na2 - na1, "\n")
cat("Propotion (%) of outliers:", round((na2 - na1) / tot*100, 1), "\n")
cat("Mean of the outliers:", round(mo, 2), "\n")
m2 <- mean(var_name, na.rm = T)
cat("Mean without removing outliers:", round(m1, 2), "\n")
cat("Mean if we remove outliers:", round(m2, 2), "\n")
response <- readline(prompt="Do you want to remove outliers and to replace with NA? [yes/no]: ")
if(response == "y" | response == "yes"){
dt[as.character(substitute(var))] <- invisible(var_name)
assign(as.character(as.list(match.call())$dt), dt, envir = .GlobalEnv)
cat("Outliers successfully removed", "\n")
return(invisible(dt))
} else{
cat("Nothing changed", "\n")
return(invisible(var_name))
}
}
outlierKD(cars,cars$speed)
head(airquality)
data <- airquality
data[4:10,3] <- rep(NA,7)
str(airquality)
data <- airquality
data[4:10,3] <- rep(NA,7)
data[1:5,4] <- NA
data <- data[-c(5,6)]
summary(data)
pMiss <- function(x) {sum(is.na(x))/length(x)*100}
apply(data,2,pMiss)
apply(data,1,pMiss)
library(mice)
md.pattern(data)
library(VIM)
install.packages("VIM")
library(VIM)
library(VIM)
aggr_plot <- aggr(data, col = c('navyblue', 'red'), numbers=TRUE, sortVars=TRUE,
labels=names(data), cex.axis=.7, gap=3,
ylab=c("Histogram of missing data", "Pattern"))
head(data)
marginplot(data[1,2])
marginplot(data[,c(1,2)])
marginmatrix(data[,c(1,2)])
marginmatrix(data)
library(Hmisc)
library(Hmisc)
data1 <- airquality
data1[4:10,3] <- rep(NA,7)
data1[1:5,4] <- NA
data1 <- data1[-c(5,6)]
summary(data1)
impute(data1$Temp,mean)
impute(data1$Ozone,median)
impute(data1$Temp,80)
data1$Temp[is.na(data1$Temp)] <- mean(data1$Temp,na.rm = TRUE)
data1$Temp[is.na(data1$Temp)]
data1$Temp
library(DMwR)
install.packages("DMwR")
library(DMwR)
actuals <- airquality$Temp[is.na(airquality$Temp)]
actuals
airquality$Temp[is.na(airquality$Temp)]
predicteds <- rep(mean(airquality$Temp, na.rm=T), length(actuals))
predicteds
regr.eval(actuals, predicteds)
summary(airquality)
predicteds <- rep(mean(data1$Temp, na.rm=T), length(actuals))
predicteds
data1 <- airquality
data1[4:10,1] <- rep(NA,7)
data1[1:5,4] <- NA
data1 <- data1[-c(5,6)]
summary(data1)
actuals <- airquality$Temp[is.na(airquality$Ozone)]
actuals
length(actuals)
predicteds <- rep(mean(data1$Ozone, na.rm=T), length(actuals))
predicteds
regr.eval(actuals, predicteds)
head(airquality)
!names(data2) %in% "Temp"
names(data2)
names(data1)
!names(data1) %in% "Temp"
knnOutput <- knnImputation(data2[,!names(data1) %in% "Temp"]])
knnOutput <- knnImputation(data2[,!names(data1) %in% "Temp"])
knnOutput <- knnImputation(data1[,!names(data1) %in% "Temp"])
head(data1)
knnOutput <- knnImputation(data1[,!names(data1) %in% "Temp"])
knnOutput <- knnImputation(data1[,!names(data1) %in% "Temp"],10)
data1[,!names(data1) %in% "Temp"]
scale(data1)
knnImputation(data1[,!names(data1) %in% "Temp"])
knnImputation(data1)
knnImputation(data1[,!names(data1) %in% "Temp"])
knnImputation(data1)
knnImputation(data1$Ozone)
knnImputation(data1$Temp)
head(data(algae))
data(algae)
head(algae)
knnImputation(algae)
str(algae)
summary(algae)
data1
knnImputation(data1)
knnImputation(airquality)
str(airquality)
str(data1)
knnImputation(airquality[,c(1:3)])
knnImputation(airquality[,c(1:4)])
data1 <- airquality
data1[4:10,1] <- rep(NA,7)
data1[1:5,4] <- NA
data1 <- data1[-c(5,6)]
knnImputation(data1)
knnImputation(airquality)
knnImputation(airquality[,-c(5,6)])
knnImputation(airquality[,-c(4,5,6)])
knnOutput <- knnImputation(airquality)
anyNA(knnOutput)
knnOutput <- knnImputation(airquality[,-4])
anyNA(knnOutput)
anyNA(knnOutput)
airquality[,-4]
summary(airquality)
data1 <- airquality
summary(data1)
pMiss <- function(x) {sum(is.na(x))/length(x)*100}
apply(data1,2,pMiss)
apply(data1,1,pMiss)
library(mice)
md.pattern(data1)
aggr_plot <- aggr(data1, col = c('navyblue', 'red'), numbers=TRUE, sortVars=TRUE,
labels=names(data), cex.axis=.7, gap=3,
ylab=c("Histogram of missing data", "Pattern"))
library(rpart)
str(data1)
data1$Month <- factor(data1$Month)
str(data1)
data1[1:5,5] <- NA
class_mod <- rpart(Month ~ .-Temp,data=BostonHousing[!is.na(data1$Month),], method="class", na.action=na.omit)
class_mod <- rpart(Month ~ .-Temp,data=data1[!is.na(data1$Month),], method="class", na.action=na.omit)
class_mod
rad_pred <- predict(class_mod, data1[is.na(data1$Month), ])
rad_pred
airquality[,5]
anove_Ozone <- rpart(Ozone ~ .-Temp,data=data1[!is.na(data1$Ozone),], method="anova", na.action=na.omit)
anove_Ozone
Ozone_pred <- predict(anove_Ozone, data1[is.na(data1$Ozone), ])
Ozone_pred
actuals <- data1$Ozone[is.na(data1$Ozone)]
actuals
predicteds <- Ozone_pred
regr.eval(actuals, predicteds)
actuals <- airquality$Month[is.na(data1$Month)]
predicteds <- month_pred
class_month <- rpart(Month ~ .-Temp,data=data1[!is.na(data1$Month),], method="class", na.action=na.omit)
month_pred <- predict(class_month, data1[is.na(data1$Month), ])
actuals <- airquality$Month[is.na(data1$Month)]
predicteds <- month_pred
regr.eval(actuals, predicteds)
predicteds <- as.numeric(colnames(month_pred)[apply(month_pred, 1, which.max)])
predicteds
actuals <- airquality$Month[is.na(data1$Month)]
actuals
mean(actuals != predicteds)
library(mice)
library(mice)
tempData <- mice(data1,m=5,maxit=50,meth='pmm',seed=500)
tempData$imp$Ozone #查看插补的数据
tempData$meth #每个变量所用的插补方法
tempData <- mice(data1,m=5,maxit=50,meth='pmm',seed=500)
head(tempData$imp$Ozone) #查看插补的数据
tempData$meth #每个变量所用的插补方法
tempData <- mice(data1,m=5,maxit=50,meth='pmm',seed=500)
completedData <- complete(tempData,1)
completedData
library(lattice)
xyplot(tempData,Ozone ~ Wind+Temp+Solar.R,pch=18,cex=1)
densityplot(tempData)
xyplot(tempData,Temp ~ Wind+Ozone+Solar.R,pch=18,cex=1)
xyplot(tempData,Ozone ~ Wind+Temp+Solar.R,pch=18,cex=1)
stripplot(tempData, pch = 20, cex = 1.2)
modelFit1 <- with(tempData,lm(Temp~ Ozone+Solar.R+Wind))
summary(pool(modelFit1))
library("recommenderlab")
m <- matrix(sample(c(as.numeric(0:5), NA), 50,
replace=TRUE, prob=c(rep(.4/6,6),.6)), ncol=10,
dimnames=list(user=paste("u", 1:5, sep=''),
item=paste("i", 1:10, sep='')))
m
r <- as(m,"realRatingMatrix")
r
str(r)
as.matrix(m)
m
as.matrix.data.frame(m)
as(m,"list")
m <- matrix(sample(c(as.numeric(0:5), NA), 50,
replace=TRUE, prob=c(rep(.4/6,6),.6)), ncol=10,
dimnames=list(user=paste("u", 1:5, sep=''),
item=paste("i", 1:10, sep='')))
as(m,"list")
as(m,"data.frame")
as(r,"data.frame")
normalize(r)
n <- normalize(r)
n
image(n,main = "Raw rating")
head(as(r,"data.frame"))
n <- normalize(r)
image(r,main = "Raw rating")
image(n,main = "normalized rating")
r_b <- binarize(r,minRating = 4)
r_b
r_b <- binarize(r,minRating = 4)
b <- as(r_b,"matrix")
b
data(MovieLense)
image(MovieLense)
hist(getRatings(MovieLense),breaks = 100)
hist(getRatings(normalize(MovieLense)),breaks = 100)
r <- data(MovieLense)
r
r <- sample(MovieLense,1000)
r <- sample(MovieLense,1000,replace = F)
r <- sample(MovieLense,1000,replace = T)
hist(rowCounts(r),breaks = 50)
str(r)
recommenderRegistry$get_entry_names()
recommenderRegistry$get_entries(dataType = "realRatingMatrix")
r_recom <- Recommender(r[1:800],method = "IBCF")
r_popul <- Recommender(r[1:800],method = "POPULAR")
names(getModel(r_recom))
names(getModel(r_popul))
getModel(r_popul)$topN
pred <- predict(r_popul,r[998:1000],n= 5)
pred
as(pred,"list")
pred3 <- bestN(pred,n = 3)
pred3
as(pred3,"list")
rate <- predict(r_popul,r[998:1000],type = "ratings")
as(rate,"matrix")
as(rate,"matrix")[,5]
as(rate,"matrix")[,1:5]
e <- evaluationScheme(r[1:800],mehod = "split",train = 0.9,given = 15,goodRating = 5)
e <- evaluationScheme(r[1:800],method = "split",train = 0.9,given = 15,goodRating = 5)
e
p1 <- predict(r1,getData(e,"known"),type = "ratings")
r1 <- Recommender(getData(e,"train"),"UBCF")
r1
p1 <- predict(r1,getData(e,"known"),type = "ratings");p1
r2 <- Recommender(getData(e,"train"),"IBCF");r2
p2 <- predict(r2,getData(e,"known"),type = "ratings");p2
calcPredictionAccuracy(p1,getD)
calcPredictionAccuracy(p1,getData(e,"unknown"))
c1 <- calcPredictionAccuracy(p1,getData(e,"unknown"))
c2 <- calcPredictionAccuracy(p2,getData(e,"unknown"))
error <- rbind(c1,c2)
error
rownames(error) <- c("UBCF","IBCF")
error
tops <- evaluationScheme(r[1:800],method = "cross",k = 4,given = 3, goodRating = 5)
tops
results <- evaluate(tops,method = "POPULAR",type = "topNList", n = c(1,3,5,10))
getConfusionMatrix(results)
avg(results)
plot(results)
plot(results,annotate = TRUE)
plot(results,"prec/rec",annotate = TRUE)
set.seed(2016)
scheme <- evaluationScheme(r,method = "split",train = 0.9,k= 1,given = 5,goodRating = 5)
scheme
scheme <- evaluationScheme(r,method = "split",train = 0.9,k= 1,given = 10,goodRating = 5)
scheme
algorithms <- list(
"random items" = list(name="RANDOM", param=NULL),
"popular items" = list(name="POPULAR", param = list(normalize = "Z-score")),
"user-based CF" = list(name="UBCF", param = list(normalize = "Z-score", method = "Cosine", nn = 25, minRating = 3)),
"item-based CF" = list(name="IBCF", param=list(k=50)),
"SVD approximation" = list(name="SVD", param=list(approxRank = 50))
)
results <- evaluate(scheme, algorithms, n = c(1, 3, 5, 10, 15, 20))
plot(results,annotate = c(1,3),legend = "bottomright")
plot(results,"prec/rec",annotate = c(2,3,4),legend = "topleft")
results2 <- evaluate(scheme,algorithms,type = "ratings")
plot(results2,ylim = c(0,100))
plot(results2,ylim = c(0,20))
plot(results2,ylim = c(0,10))
plot(results2,ylim = c(0,20))
library("recommenderlab")
m <- matrix(sample(c(as.numeric(0:5), NA), 50,
replace=TRUE, prob=c(rep(.4/6,6),.6)), ncol=10,
dimnames=list(user=paste("u", 1:5, sep=''),
item=paste("i", 1:10, sep='')))
m
r <- as(m,"realRatingMatrix")
r
m;r
r <- sample(MovieLense,943,replace = F)
hist(getRatings(normalize(MovieLense)),breaks = 100)
hist(rowCounts(r),breaks = 50)
image(MovieLense)
r_recom <- Recommender(r,method = "IBCF")
r_popul <- Recommender(r,method = "POPULAR")
names(getModel(r_recom))
getModel(r_popul)$topN
e <- evaluationScheme(r[1:800],method = "split",train = 0.9,given = 15,goodRating = 5)
r1 <- Recommender(getData(e,"train"),"UBCF");r1
p1 <- predict(r1,getData(e,"known"),type = "ratings");p1
r2 <- Recommender(getData(e,"train"),"IBCF");r2
p2 <- predict(r2,getData(e,"known"),type = "ratings");p2
c1 <- calcPredictionAccuracy(p1,getData(e,"unknown"))
c2 <- calcPredictionAccuracy(p2,getData(e,"unknown"))
error <- rbind(c1,c2)
rownames(error) <- c("UBCF","IBCF")
error
library(DMwR)
data(sales)
head(sales)
summary(sales)
str(sales)
sum(is.na(sales$Quant)&is.na(sales$Val))
table(sales$Insp)/nrow(sales)*100
totS <- table(sales$ID)
totS
barplot(totS,main='Transactions per salespeople',names.arg='',xlab='Salespeople',ylab='Amount')
sales$Uprice <- sales$Val/sales$Quant
summary(sales$Uprice)
library(qcc)
install.packages("qcc")
library(qcc)
library(qcc)
table(sales$Insp)/nrow(sales)*100
upp <- aggregate(sales$Uprice,list(sales$Prod),median,na.rm= T)
View(upp)
order(upp[,2],decreasing = O)[1:5]
order(upp[,2],decreasing = T)[1:5]
upp[order(upp[,2],decreasing = T)[1:5],1]
upp <- aggregate(sales$Uprice,list(sales$Prod),median,na.rm= T)
topP <- sapply(c(T,F), function(o)
upp[order(upp[,2],decreasing = o)[1:5],1])
colnames(topP)<- c("Expensive","Cheap")
topP
tops <- sales[Prod %in% topP[1,],c("Prod","Uprice")]
tops <- sales[sales$Prod %in% topP[1,],c("Prod","Uprice")]
tops
boxplot(tops$Uprice ~ tops$Prod,ylab = "Uprice",log = "y")
tops$Prod <- factor(tops$Prod)
boxplot(tops$Uprice ~ tops$Prod,ylab = "Uprice",log = "y")
str(sales)
out <- tapply(sales$Uprice,list(Prod = sales$Prod),
function(x) length(boxplot.stats(x)$out))
out
out[order(out,decreasing = T)[1:10]]
sales$Uprice["p580"]
sales["p580","Uprice"]
sales[Prod =="p580","Uprice"]
sales[sales$Prod =="p580","Uprice"]
sol <- qcc(sales[sales$Prod =="p580","Uprice"],type = "xbar.one")
sol <- qcc(sales[sales$Prod =="p560","Uprice"],type = "xbar.one")
sol <- qcc(sales[sales$Prod =="p3689","Uprice"],type = "xbar.one")
sol <- qcc(sales[sales$Prod =="p3689","Uprice"],type = "S")
sol <- qcc(sales[sales$Prod =="p580","Uprice"],type = "xbar")
sol <- qcc(sales[sales$Prod =="p580","Uprice"],type = "xbar.one")
sol$statistics
sol$limits
library(DMwR)
head(sales)
test <- sales[,c(3,4)]
outlier <- lofactor(test,k = 5)
sales2 <- sales[-which(is.na(sales$Quant) & is.na(sales$Val)),]
test <- sales2[,c(3,4)]
outlier <- lofactor(test,k = 5)
anyNA(test)
is.na(sales2)
test <- as.matrix(sales2[,c(3,4)])
head(test)
test <- as.matrix(sales2[,c(3,4)])
outlier <- lofactor(test,k = 5)
outlier <- lofactor(test,k = 2)
data(iris)
lof.scores <- lofactor(iris[,-5],10)
lof.scores
lof.scores
iris[,-5]
outlier <- lofactor(test,k = 2)
anyNA(test)
scale(test)
sales2 <- sales[-which(is.na(sales$Quant) | is.na(sales$Val)),]
test <- as.matrix(sales2[,c(3,4)])
outlier <- lofactor(test,k = 2)
test <- as.double(as.matrix(sales2[,c(3,4)]))
outlier <- lofactor(test,k = 2)
outlier <- as.double(lofactor(test,k = 2))
test <- as.matrix(sales2[1:1000,c(3,4)])
outlier <- lofactor(test,k = 2)
plot(density(outlier))
outlier <- lofactor(test,k = 2)
anyNA(outlier)
is.na(outlier)
outlier <- outlier[-is.na(outlier),]
outlier <- outlier[-which(is.na(outlier)),]
dim(outlier)
class
class(outlier)
which(is.na(outlier))
outlier <- outlier[-which(is.na(outlier))]
plot(density(outlier))
test <- as.matrix(sales2[1:1000,c(3,4)])
outlier <- lofactor(test,k = 5)
outlier <- outlier[-which(is.na(outlier))]
outlier <- lofactor(test,k = 5)
anyNA(outlier)
plot(density(outlier))
outliers <- order(outlier,decreasing = T)[1:5]
outliers
rm(iris)
pch <- rep(".",nrow(test))
pch[outlier]<- "+"
col <- rep("black",nrow(test))
col[outlier]<- "red"
plot(test,pch= pch, col = col)
head
head(test)
test <- sales2[1:1000,c(3,4)]
plot(log(test$Quant),log(test$Val),pch= pch, col = col)
pch <- rep(".",nrow(test))
pch[outlier]<- "+"
col <- rep("black",nrow(test))
col[outlier]<- "red"
labels <- 1:nrow(test)
labels[-outlier]<- "."
plot(log(test$Quant),log(test$Val),pch= pch, col = col,cex = 1.2,xlabs = labels)
plot(log(test$Quant),log(test$Val),pch= pch, col = col,cex = 1.2,labels = labels)
plot(log(test$Quant),log(test$Val),pch= pch, col = col,cex = 1.2,label = labels)
labels <- 1:nrow(test)
labels[-outlier]<- "."
plot(log(test$Quant),log(test$Val),pch= pch, col = col,cex = 1.2,xlabs= labels)
outlier
order(outlier)
data(sales)
sales$Uprice <- sales$Val/sales$Quant
head(sales2)
sales2 <- sales[-which(is.na(sales$Quant) | is.na(sales$Val)),]
head(sales2)
sales2[ID == v1,prod == p1]
str(sales2)
sales2[ID == "v1",prod == "p1"]
sales2[ID == "v1"& prod == "p1"]
sales2[sales2$ID == "v1"& sales$prod == "p1"]
table(sales2$ID,sales2$Prod)
sales2[sales$prod == "p1",]
head(sales2)
sales$prod == "p1"
sales3 <- sales2[sales$Prod == "p1",]
sales3
str(sales3)
sales3$Prod <- factor(sales3$Prod)
str(sales3)
sales3 <- sales2[sales$Prod == "p1","uprice"]
sales3 <- sales2[sales$Prod == "p1","uprice"]
sales3 <- sales2[sales$Prod == "p1",]
head(sales3)
nlevels(sales3$Prod)
sales3$Prod <- factor(sales3$Prod)
nlevels(sales3$Prod)
kmean <- kmeans(sales3$Uprice,18)
kmean$centers
centers <- kmean$centers[kmean$cluster,]
centers
distances <- sqrt(rowSums((sales3$Uprice-centers)^2))
sales3 <- sales2[sales$Prod == "p1","Uprice"]
sales3
kmean <- kmeans(sales3$Uprice,18)
kmean <- kmeans(sales3,18)
kmean$centers
centers <- kmean$centers[kmean$cluster,]
kmean$cluster
centers <- kmean$centers[kmean$cluster,]
centers
kmean$centers
distances <- sqrt(rowSums((sales3-centers)^2))
sales3 <- sales2[sales$Prod == "p1",]
sales3$Prod <- factor(sales3$Prod)
head(sales3)
library(DMwR)
setwd("C:/Users/HP/Desktop/datasciences/数据处理/离群点")
Encoding("liqndian.Rmd")
Encoding("liqndian.Rmd") <- "UTF-8"

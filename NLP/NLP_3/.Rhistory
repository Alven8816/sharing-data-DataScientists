library(text2vec)
setwd("F:/R/datasciences/NLP/NLP_3")
library(text2vec)
library(data.table)
data("movie_review")
setDT(movie_review)
View(movie_review)
setkey(movie_review, id)
set.seed(2016L)
all_ids = movie_review$id
train_ids = sample(all_ids, 4000)
test_ids = setdiff(all_ids, train_ids)
train = movie_review[J(train_ids)]
test = movie_review[J(test_ids)]
prep_fun = tolower
#代表词语划分到什么程度
tok_fun = word_tokenizer
#步骤1.设置分词迭代器
it_train = itoken(train$review,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = train$id,
progressbar = FALSE)
#步骤2.分词
vocab = create_vocabulary(it_train)
#步骤3.设置形成语料文件
vectorizer = vocab_vectorizer(vocab)
#步骤4.构建DTM矩阵
dtm_train = create_dtm(it_train, vectorizer)
library(glmnet)
NFOLDS = 4
library(glmnet)
NFOLDS = 4
glmnet_classifier = cv.glmnet(x = dtm_train, y = train[['sentiment']],
family = 'binomial',
# L1 penalty
alpha = 1,
# interested in the area under ROC curve
type.measure = "auc",
# 5-fold cross-validation
nfolds = NFOLDS,
# high value is less accurate, but has faster training
thresh = 1e-3,
# again lower number of iterations for faster training
maxit = 1e3)
plot(glmnet_classifier)
it_test = test$review %>%
prep_fun %>%
tok_fun %>%
itoken(ids = test$id,
# turn off progressbar because it won't look nice in rmd
progressbar = FALSE)
dtm_test = create_dtm(it_test, vectorizer)
preds = predict(glmnet_classifier, dtm_test, type = 'response')[,1]
glmnet:::auc(test$sentiment, preds)

inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433);data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]];training = adData[ inTrain,]
testing = adData[-inTrain,]
head(training)
View(training)
preProc <- preProcess(training[,-1],method = "pca",pcaComp = 8)
preProc
trainpc <- predict(preProc,training[,-1])
head(trainpc)
dim(trainpc)
modelFit <- train(training$diagnosis ~ .,method="glm",data = trainpc)
head(modelFit)
testpc <- predict(preProc, testing[,-1])
confusionMatrix(testing$diagnosis,predict(modelFit,testpc))
View(training)
names(training)
grep("^[I][L]", names(training))
col_il <- grep("^[I][L]", names(training))
c(1,col_il)
training <- training[,c(1,col_il)]
preProc <- preProcess(training[,-1],method = "pca",
pcaComp = 7)
trainpc <- predict(preProc,training[,-1])
modelFit <- train(training$diagnosis ~ .,method="glm",
data = trainpc)
testpc <- predict(preProc, testing[,-1])
confusionMatrix(testing$diagnosis,predict(modelFit,testpc))
preProc <- preProcess(training[,-1],method = "pca",
pcaComp = 9)
trainpc <- predict(preProc,training[,-1])
modelFit <- train(training$diagnosis ~ .,method="glm",
data = trainpc)
testpc <- predict(preProc, testing[,-1])
confusionMatrix(testing$diagnosis,predict(modelFit,testpc))
preProc <- preProcess(training[,-1],method = "pca",
pcaComp = 10)
trainpc <- predict(preProc,training[,-1])
modelFit <- train(training$diagnosis ~ .,method="glm",
data = trainpc)
testpc <- predict(preProc, testing[,-1])
confusionMatrix(testing$diagnosis,predict(modelFit,testpc))
preProc <- preProcess(training[,-1],method = "pca",
pcaComp = 11)
trainpc <- predict(preProc,training[,-1])
modelFit <- train(training$diagnosis ~ .,method="glm",
data = trainpc)
testpc <- predict(preProc, testing[,-1])
confusionMatrix(testing$diagnosis,predict(modelFit,testpc))
preProc <- preProcess(training[,-1],method = "pca",
thresh = 0.8)
preProc
preProc <- preProcess(training[,-1],method = "pca",
pcaComp = 7)
trainpc <- predict(preProc,training[,-1])
modelFit <- train(training$diagnosis ~ .,method="glm",
data = trainpc)
testpc <- predict(preProc, testing[,-1])
confusionMatrix(testing$diagnosis,predict(modelFit,testpc))
View(training)
model_GLM <- train(diagnosis ~.,data = training,method="glm")
testing  <- testing [,c(1,col_il)]
pred <- predict(model_GLM,testing)
confusionMatrix(testing$diagnosis,pred)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
View(predictors)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
View(predictors)
preProc <- preProcess(training[,-1],method = "pca",
thresh = 0.9)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
#Find all the predictor variables in the training
#set that begin with IL
col_il <- grep("^[I][L]", names(training))
training <- training[,c(1,col_il)]
testing  <- testing [,c(1,col_il)]
preProc <- preProcess(training[,-1],method = "pca",
thresh = 0.9)
preProc
getwd
getwd（）
getwd()
library(shinyapps)
shinyapps::deployApp(appDir = "C:\\Users\\HP\\Documents\\coursera\\coursera project 9 Developing Data Products\\shinyapp")
head(cars)
ccars
cars
data()
sleep
AirPassengers
Galton
data(Galton)
data()
mpg
data(mpg)
library(ggplot2)
mpg
mpg
library(dplyr)
tbl_df(mpg)
getwd()
library(plyr)
library(dplyr)
library(randomForest)
data <- iris
glimpse(data)
k = 5
data$id <- sample(1:k, nrow(data),replace = TRUE)
head(data)
list <- 1:k
list
prediction <- data.frame()
testsetCopy <- data.frame()
progress.bar <- create_progress_bar("text")
progress.bar$init(k)
for(i in 1:k){
# 删除id为i的行，创建训练集
# 选id为i的行，创建测试集
trainingset <- subset(data,id %in% list[-i])
testset <- subset(data,id %in% c(i))
#运行一个随机森林模型
mymodel <- randomForest(trainingset$Sepal.Length ~ .,
data = trainingset,ntree = 100)
#去掉应变量（列1）, Sepal.Length
temp <- as.data.frame(predict(mymodel,testset[,-1]))
# 将迭代出的预测结果添加到预测数据框的末尾
prediction <- rbind(prediction,temp)
# 将迭代出的测试集结果添加到测试集数据框的末尾
# 只保留Sepal Length一列
testsetCopy <- rbind(testsetCopy,as.data.frame(testset[,1]))
progress.bar$step()
}
result <- cbind(prediction,testsetCopy[,1])
View(result)
names(result) <- c("Predicted","Actual")
View(result)
dim(result)
result$Difference <- abs(result$Actual- result$Predicted)
# 用误差的绝对平均值作为评估
View(result)
summary(result$Difference)
library(caret)
confusionMatrix(result$Predicted,result$Actual)
library(ggplot2)
set.seed(1410)
dsmall <- diamonds[sample(nrow(diamonds),100),]
qplot(carat,price,data = diamonds)
library(ggplot2)
set.seed(1410)
dsmall <- diamonds[sample(nrow(diamonds),100),]
# 2.3 基本用法
qplot(carat,price,data = diamonds)
qplot(log(carat),log(price),data = diamonds)
qplot(carat, x * y * z, data = diamonds)
qplot(carat, price, data = dsmall, colour = color)
qplot(carat, price, data = dsmall, shape = cut)
qplot(carat, price, data = diamonds, alpha = I(1/10))
qplot(carat, price, data = diamonds, alpha = I(1/100))
qplot(carat, price, data = dsmall, geom = c("point", "smooth"))
qplot(carat, price, data = dsmall, geom = c("point", "smooth"),
span = 0.2)
qplot(carat, price, data = dsmall, geom = c("point", "smooth"),
span = 1)
library(mgcv)
library(mgcv)
qplot(carat, price, data = dsmall, geom = c("point", "smooth"),
method = "gam", formula = y ~ s(x))
library(ggplot2)
qplot(carat, price, data = dsmall, geom = c("point", "smooth"),
method = "gam", formula = y ~ s(x))
qplot(carat, price, data = dsmall, geom = c("point", "smooth"),
method = "gam", formula = y ~ s(x))
qplot(carat, price, data = dsmall, geom = c("point", "smooth"),
method = "gam", formula = y ~ s(x, bs = "cs"))
library(splines)
qplot(carat, price, data = dsmall, geom = c("point", "smooth"),
method = "lm")
library(splines)
qplot(carat, price, data = dsmall, geom = c("point", "smooth"))
library(splines)
qplot(carat, price, data = dsmall, geom = c("point", "smooth"),method = "lm")
qplot(carat, price, data = dsmall, geom = c("point", "smooth"),
method = "lm", formula = y ~ ns(x,5))
qplot(color, price / carat, data = diamonds, geom = "jitter")
qplot(color, price / carat, data = diamonds, geom = "boxplot")
qplot(carat, data = diamonds, geom = "histogram")
qplot(carat, data = diamonds, geom = "density")
qplot(carat, data = diamonds, geom = "density", colour = color)
qplot(carat, data = diamonds, geom = "histogram", fill = color)
qplot(color, data = diamonds, geom = "bar")
qplot(color, data = diamonds, geom = "bar", weight = carat) +
scale_y_continuous("carat")
qplot(color, data = diamonds, geom = "bar", weight = carat)
qplot(date, unemploy / pop, data = economics, geom = "line")
qplot(date, uempmed, data = economics, geom = "line")
year <- function(x) as.POSIXlt(x)$year + 1900
qplot(unemploy / pop, uempmed, data = economics,
geom = c("point", "path"))
qplot(unemploy / pop, uempmed, data = economics,
geom = "path", colour = year(date)) + scale_area()
qplot(unemploy / pop, uempmed, data = economics,
geom = "path", colour = year(date)) + scale_area()
qplot(unemploy / pop, uempmed, data = economics,
geom = "path", colour = year(date))
+ scale_area()
qplot(carat, data = diamonds, facets = color ~ .,
geom = "histogram", binwidth = 0.1, xlim = c(0, 3))
qplot(carat, ..density.., data = diamonds, facets = color ~ .,
geom = "histogram", binwidth = 0.1, xlim = c(0, 3))
qplot(
carat, price, data = dsmall,
xlab = "Price ($)", ylab = "Weight (carats)",
main = "Price-weight relationship"
)
qplot(
carat, price/carat, data = dsmall,
ylab = expression(frac(price,carat)),
xlab = "Weight (carats)",
main="Small diamonds",
xlim = c(.2,1)
)
qplot(carat, price, data = dsmall, log = "xy")
qplot(displ, hwy, data = mpg, colour = factor(cyl))
qplot(displ, hwy, data=mpg, colour=factor(cyl), geom="line") +
opts(drop = "legend_box")
qplot(displ, hwy, data=mpg, colour=factor(cyl), geom="bar",
stat="identity", position = "identity")
qplot(displ, hwy, data=mpg, colour=factor(cyl)) +
geom_smooth(data= subset(mpg, cyl != 5), method="lm")
qplot(displ, hwy, data=mpg, facets = . ~ year) + geom_smooth()
x <- 1:10
y <- factor(letters[1:5])
qplot(x, x, size = x) + opts(keep = "legend_box")
x <- 1:10
y <- factor(letters[1:5])
qplot(x, x, size = x)
x1 <- c(1,10)
y1 <- c(1, 5)
p <- qplot(x1, y1, geom="blank", xlab=NULL, ylab=NULL)
+ theme_bw()
p <- qplot(x1, y1, geom="blank", xlab=NULL, ylab=NULL) + theme_bw()
p
p + coord_trans(y="log10")
p + coord_polar()
p <- qplot(displ, hwy, data = mpg, colour = factor(cyl))
summary(p)
getwd()
![](http://cos.name/wp-content/uploads/2012/03/simpson.png)
n <- 100
x2 <- 1:n
x1 <- .01 *x2 +runif(n,-.1,.1)
y = -x1+x2 +rnorm(n,sd=  .01)
summary(lm(y ~ x1))$coef
summary(lm(y ~ x1 +x2))$coef
dat = data.frame(y = y, x1 = x1,x2 = x2,ey = resid(lm(y ~ x2)),ex1 = resid(lm(x1 ~ x2)))
library(ggplot2)
g = ggplot(dat, aes(y = y,x = x1, colour = x2))
g = g + geom_point(colour = "grey50", size = 5)+ geom_smooth(method = lm,se = FALSE, colour = "brack")+ geom_point(size = 4)
g
g = g + geom_point(colour = "grey50", size = 5)+ geom_smooth(method = lm,se = FALSE, colour = "black")+ geom_point(size = 4)
g
g = g + geom_point(colour = "grey50", size = 5)+ geom_smooth(method = lm,se = FALSE, colour = "black")+ geom_point(size = 4)
g
rm(g)
g = ggplot(dat, aes(y = y,x = x1, colour = x2))
g = g + geom_point(colour = "grey50", size = 5)+ geom_smooth(method = lm,se = FALSE, colour = "black")+ geom_point(size = 4)
g
g2 = ggplot(dat, aes(y = ey, x = ex1 ,color = x2))
g2 = g2 + geom_point(colour = "grey50",size = 5)+ geom_smooth(method = lm,se = FALSE, color = "black")+ geom_point(size = 4)
g2
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(ozone)
data(ozone)
head(ozone)
str(ozone)
dim(ozone)
sample(1:dim(ozone)[1],replace = TRUE)
ozone0 <- ozone[ss,]
ss <- sample(1:dim(ozone)[1],replace = TRUE)
ozone0 <- ozone[ss,]
ozone0
ozone0 <- ozone0[order(ozone0$ozone),]
head(ozone0)
plot(ozone$ozone,ozone$temperature,pch= 19,cex = 0.5)
for(i in 1:10){
lines(1:155,ll[i,],col= "grey",lwd = 2)
}
ll <- matrix(NA,nrow = 10, ncol = 155)
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace = TRUE)
ozone0 <- ozone[ss,]
ozone0 <- ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone,data = ozone0, span = 0.2)
ll[i,] <- predict(loess0, newdata = data.frame(ozone = 1:155))
}
plot(ozone$ozone,ozone$temperature,pch= 19,cex = 0.5)
for(i in 1:10){
lines(1:155,ll[i,],col= "grey",lwd = 2)
}
lines(1:155,apply(ll,2,mean),col = "red",lwd = 2)
library(caret)
predictors <- data.frame(ozone = ozone$ozone)
temperature <- ozone$temperature
library(caret)
library(ggplot2)
modFit <- train(Species ~ ., data = training,method = "rf",prox = TRUE)
inTrain <- createDataPartition(y = iris$Species,p = 0.7,list = FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
library(caret)
modFit <- train(Species ~ ., data = training,method = "rf",prox = TRUE)
modFit
getTree(modFit$finalModel,k = 2)
irisp <- classCenter(training[,c(3,4)],training$Species,modFit$finalModel$prox)
irisp
irisp <- as.data.frame(irisp)
irisp
irisp$Species <- rownames(irisp)
irisp
p <- qplot(petal.Width,Petal.Length , col = Species,data = training)
p
p <- qplot(Petal.Width,Petal.Length , col = Species,data = training)
p
p + geom_point(aes(x = Petal.With,y = Petal.Length,col = Species),size = 5, shape = 4, data = irisp)
p + geom_point(aes(x = Petal.Width,y = Petal.Length,col = Species),size = 5, shape = 4, data = irisp)
pred <- predict(modFit,testing)
testing$predRight <- pred == testing$Species
table(pred,testing$Species)
qplot(Petal.Width,Petal.Length,color = predRight,data = testing, main = "new data predictions")
modFit2 <- train(Species ~ . ,method = "rpart",data = training)
library(caret)
modFit2 <- train(Species ~ . ,method = "rpart",data = training)
print(modFit2$finalModel)
plot(modFit2$finalModel, uniform = TRUE,main = "classification tree")
test(modFit2$finalModel, use.n = TRUE,all = TRUE,cex = .7)
text(modFit2$finalModel, use.n = TRUE,all = TRUE,cex = .7)
install.packages("rattle")
library(rattle)
library(rattle)
fancyRpartPlot(modFit2$finalModel)
fancyRpartPlot(modFit2$finalModel)
fancyRpartPlot()
fancyRpartPlot(modFit2$finalModel)
plot(modFit2$finalModel, uniform = TRUE,main = "classification tree")
text(modFit2$finalModel, use.n = TRUE,all = TRUE,cex = .7)
library(rattle)
fancyRpartPlot(modFit2$finalModel)
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(modFit2$finalModel)
predict(modFit2,newdata = testing)
installed.packages(c("AppliedPredictiveModeling","caret","ElemStatLearn","pgmm","rpart"))
installed.packages(c("AppliedPredictiveModeling"))
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(caret)
data(segmentationOriginal)
str(segmentationOriginal)
set.seed(125)
intrain <- createDataPartition(segmentationOriginal$Case,
p = 0.7,
list = FALSE)
training <- segmentationOriginal[intrain,]
testing <- segmentationOriginal[-intrain,]
str(training)
NROW(segmentationOriginal)
NROW(training)
NROW(testing)
getModelInfo()
fit <- train(case ~ .,data = training,method = "rpart")
fit <- train(Case ~ .,data = training,method = "rpart")
str(segmentationOriginal)
names(segmentationOriginal)
fit$finalModel
predicts <- predict(fit,newdata = testing)
predicts
plot(fit$finalModel)
text(fit$finalModel)
library(rattle)
fancyRpartPlot(fit$finalModel)
str(segmentationOriginal)
nrow(segmentationOriginal$Case =="Test")
nrow(segmentationOriginal$Case == 1)
segmentationOriginal[Case == 1,]
segmentationOriginal["Case" == 1,]
mode(segmentationOriginal$Case)
table(segmentationOriginal$Case)
intrain <- createDataPartition(segmentationOriginal$Case,
p = 0.5,
list = FALSE)
training <- segmentationOriginal[intrain,]
testing <- segmentationOriginal[-intrain,]
fit <- train(class ~ .,data = training,method = "rpart")
str(training)
fit <- train(Class ~ .,data = training,method = "rpart")
library(rattle)
fancyRpartPlot(fit$finalModel)
fit$finalModel
fit <- train(Class ~ .,data = training,method = "rpart")
fancyRpartPlot(fit$finalModel)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
head(olive)
str(olive)
fit2 <- train(Area ~ .,data = olive,method = "rpart")
str(olive$Area)
class(olive$Area)
table(olive$Area)
fit2 <- train(as.factor(Area) ~ .,data = olive,method = "rpart")
colMeans(olive)
t(colMeans(olive)))
t(colMeans(olive))
predict(fit2,newdata = as.data.frame(t(colMeans(olive))))
fancyRpartPlot(fit2$finalModel)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
dim(SAheart)
dim(SAheart)[1]/2
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
str(trainSA)
fit3 <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm",family="binomial")
fit3 <- train(as.factor(chd) ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm",family="binomial")
predicts <- predict(fit3, newdata = "testSA")
str(testSA)
predicts <- predict(fit3, newdata = "testSA")
predicts <- predict(fit3, newdata = "testSA ")
fit3 <- train(as.factor(chd) ~ as.numerbic(age) + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm",family="binomial")
fit3 <- train(as.factor(chd) ~ as.numeric(age) + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm",family="binomial")
fit$finalModel
fit3$finalModel
predicts <- predict(fit3, newdata = "testSA ")
testSA
predicts <- predict(fit3, newdata = testSA )
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd,predicts)
install.packages("ElemStatLearn")
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train)
vowel.test$y <- as.factor(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
fit4 <- train(y ~ ., method = "rf",data = vowel.train)
fit4$finalModel
fit4$method
fit4$modelInfo
fit4$modelType
fit4$results
fit4$pred
fit4$bestTune
fit4$dots
fit4$metric
fit4$control
?varlmp
??varlmp
varlmp(fit4)
varImp.plsda(fit4)
varImp.plsda(fit4)
varImp.plsda(fit4,useModel = "rf")
varlmp(fit4$finalModel)
varImp.plsda(fit4$finalModel)
show(iris)
getwd()
setwd("C:\\Users\\HP\\Documents\\visualzing data test\\地址解析")
accident <- read.table("accident.txt",header = TRUE)
accident <- read.table("accident.txt",header = TRUE)
accident <- read.table("accident.txt")
read.csv2("accident.txt")
accident <- read.table("accident.txt",header = TRUE,sep = ",")
accident <- read.table("accident.txt",header = FALSE,sep = ",",col.name = c("id","SGBH","DMSM1","SGDD","SGFSSJ1"))
accident <- read.table("accident.csv",header = FALSE)
accident <- read.table("accident.csv",header = TURE)
accident <- read.table("accident.csv",header = TRUE)
accident <- read.table("accident.csv",header = TRUE)
